# -*- coding: utf-8 -*-
"""Audio Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EcTDh-p42tG21nQhb7ri4o-e41lD6lsh
"""

# Import generic libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

!pip install pydub

# Import AudioSegment and play
from pydub import AudioSegment

AudioSegment.converter = "Downloads/ffmpeg"
AudioSegment.ffmpeg = "Downloads/ffmpeg"
AudioSegment.ffprobe ="Downloads/ffprobe"

from pydub.playback import play

# Create an AudioSegment instance
raw_file01 = AudioSegment.from_file(file="/content/exemplo01.wav", format="wav")
raw_file02 = AudioSegment.from_file(file="/content/exemplo02.wav", format="wav")

# Check the type
print(type(raw_file01))
print(type(raw_file02))

# Play the audio file
# play(wav_file)

import librosa
import IPython.display as ipd

x01, sr01 = librosa.load('/content/exemplo01.wav')
ipd.Audio(x01, rate=sr01)

x02, sr02 = librosa.load('/content/exemplo02.wav')
ipd.Audio(x02, rate=sr02)

"""Get general information of the audio"""

from pydub import AudioSegment

# Load files
audio_segment01 = AudioSegment.from_file('/content/exemplo01.wav')

# Print attributes
print(f"Channels: {audio_segment01.channels}")
print(f"Sample width: {audio_segment01.sample_width}")
print(f"Frame rate (sample rate): {audio_segment01.frame_rate}")
print(f"Frame width: {audio_segment01.frame_width}")
print(f"Length (ms): {len(audio_segment01)}")
print(f"Frame count: {audio_segment01.frame_count()}")
print(f"Intensity: {audio_segment01.dBFS}")

# Load files
audio_segment02 = AudioSegment.from_file('/content/exemplo02.wav')

# Print attributes
print(f"Channels: {audio_segment02.channels}")
print(f"Sample width: {audio_segment02.sample_width}")
print(f"Frame rate (sample rate): {audio_segment02.frame_rate}")
print(f"Frame width: {audio_segment02.frame_width}")
print(f"Length (ms): {len(audio_segment02)}")
print(f"Frame count: {audio_segment02.frame_count()}")
print(f"Intensity: {audio_segment02.dBFS}")

"""Amplitude"""

import wave

# Open wav file and read frames as bytes
sf_filewave01 = wave.open('/content/exemplo01.wav', 'r')
signal_sf01 = sf_filewave01.readframes(-1)

# Convert audio bytes to integers
soundwave_sf01 = np.frombuffer(signal_sf01, dtype='int16')

# Get the sound wave frame rate
framerate_sf01 = sf_filewave01.getframerate()

# Find the sound wave timestamps
time_sf01 = np.linspace(start=0,
                      stop=len(soundwave_sf01)/framerate_sf01,
                      num=len(soundwave_sf01))

# Open wav file and read frames as bytes
sf_filewave02 = wave.open('/content/exemplo02.wav', 'r')
signal_sf02 = sf_filewave02.readframes(-1)

# Convert audio bytes to integers
soundwave_sf02 = np.frombuffer(signal_sf02, dtype='int16')

# Get the sound wave frame rate
framerate_sf02 = sf_filewave02.getframerate()

# Find the sound wave timestamps
time_sf02 = np.linspace(start=0,
                      stop=len(soundwave_sf02)/framerate_sf02,
                      num=len(soundwave_sf02))

f, ax = plt.subplots(figsize=(15, 9), nrows=2, sharex=True)

# Add the audio data to the plot
ax[0].set(title='Exemplo 01', ylabel='Amplitude')
ax[0].plot(time_sf01, soundwave_sf01, label='Exemplo 01', alpha=0.5)

# Add the audio data to the plot
ax[1].set(title='Exemplo 02', ylabel='Amplitude')
ax[1].plot(time_sf02, soundwave_sf02, label='Exemplo 02', alpha=0.5)

"""Amplitude envelope"""

import librosa

audio_data01 = '/content/exemplo01.wav'
x01 , sr01 = librosa.load(audio_data01, sr=None)

audio_data02 = '/content/exemplo02.wav'
x02 , sr02 = librosa.load(audio_data02, sr=None)

!pip install librosa.display

# Plot amplitude envelope
import librosa.display

plt.figure(figsize=(15, 3))
librosa.display.waveplot(x01, sr=sr01)

plt.figure(figsize=(15, 3))
librosa.display.waveplot(x02, sr=sr02)

"""Spectogram"""

x01, sr01 = librosa.load('/content/exemplo01.wav')

X01 = librosa.stft(x01)
Xdb01 = librosa.amplitude_to_db(abs(X01))
plt.figure(figsize=(15, 3))
librosa.display.specshow(Xdb01, sr=sr01, x_axis='time', y_axis='hz')
plt.colorbar()

x02, sr02 = librosa.load('/content/exemplo02.wav')

X02 = librosa.stft(x02)
Xdb02 = librosa.amplitude_to_db(abs(X02))
plt.figure(figsize=(15, 3))
librosa.display.specshow(Xdb02, sr=sr02, x_axis='time', y_axis='hz')
plt.colorbar()

"""Feature Extraction

RMS/Energy - Compute root-mean-square (RMS) value for each frame, total magntiude of the signal. For audio signals, that roughly corresponds to how loud the signal is. https://en.wikipedia.org/wiki/Energy_(signal_processing%29
"""

y01, sr01 = librosa.load('/content/exemplo01.wav')
S01, phase01 = librosa.magphase(librosa.stft(y01))
rms01 = librosa.feature.rms(S=S01)
fig01, ax01 = plt.subplots(figsize=(15, 6), nrows=2, sharex=True)
times01 = librosa.times_like(rms01)
ax[0].semilogy(times01, rms01[0], label='RMS Energy')
ax[0].set(xticks=[])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S01, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')

y02, sr02 = librosa.load('/content/exemplo02.wav')
S02, phase02 = librosa.magphase(librosa.stft(y02))
rms02 = librosa.feature.rms(S=S02)
fig02, ax02 = plt.subplots(figsize=(15, 6), nrows=2, sharex=True)
times02 = librosa.times_like(rms02)
ax[0].semilogy(times02, rms02[0], label='RMS Energy')
ax[0].set(xticks=[])
ax[0].legend()
ax[0].label_outer()
librosa.display.specshow(librosa.amplitude_to_db(S02, ref=np.max),
                         y_axis='log', x_axis='time', ax=ax[1])
ax[1].set(title='log Power spectrogram')

"""Zero crossing rate

The zero-crossing rate (ZCR) is the rate at which a signal changes from positive to zero to negative or from negative to zero to positive.[1] Its value has been widely used in both speech recognition and music information retrieval, being a key feature to classify percussive sounds. https://en.wikipedia.org/wiki/Zero-crossing_rate

It usually has higher values for highly percussive sounds like those in metal and rock
"""

y01, sr01 = librosa.load('/content/exemplo01.wav')
zcrs01 = librosa.feature.zero_crossing_rate(y01)
print(f"Zero crossing rate: {sum(librosa.zero_crossings(y01))}")

plt.figure(figsize=(15, 3))
plt.plot(zcrs01[0])
plt.title('Exemplo 01')

print(sum(librosa.zero_crossings(y01)))

x01, sr01 = librosa.load('/content/exemplo01.wav')

#Plot the signal:
plt.figure(figsize=(14, 5))
librosa.display.waveplot(x01, sr=sr01)

# Zooming in
n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x01[n0:n1])
plt.grid()

y02, sr02 = librosa.load('/content/exemplo02.wav')
zcrs02 = librosa.feature.zero_crossing_rate(y02)
print(f"Zero crossing rate: {sum(librosa.zero_crossings(y02))}")

plt.figure(figsize=(15, 3))
plt.plot(zcrs02[0])
plt.title('Exemplo 02')

print(sum(librosa.zero_crossings(y02)))

x02, sr02 = librosa.load('/content/exemplo02.wav')

#Plot the signal:
plt.figure(figsize=(14, 5))
librosa.display.waveplot(x02, sr=sr02)

# Zooming in
n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x02[n0:n1])
plt.grid()

"""Mel-Frequency Cepstral Coefficients (MFCCs)

Mel-Frequency Cepstral Coefficients (MFCCs)
The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10â€“20) which concisely describe the overall shape of a spectral envelope. It models the characteristics of the human voice.
"""

x01, sr01 = librosa.load('/content/exemplo01.wav')
mfccs01 = librosa.feature.mfcc(x01, sr=sr01)

#Displaying  the MFCCs:
fig01,ax01 = plt.subplots(figsize=(15, 3))
img01 = librosa.display.specshow(mfccs01, sr=sr01, x_axis='time')
fig01.colorbar(img01, ax=ax01)
ax.set(title='Exemplo 01')

x02, sr02 = librosa.load('/content/exemplo02.wav')
mfccs02 = librosa.feature.mfcc(x02, sr=sr02)

#Displaying  the MFCCs:
fig02,ax02 = plt.subplots(figsize=(15, 3))
img02 = librosa.display.specshow(mfccs02, sr=sr02, x_axis='time')
fig02.colorbar(img02, ax=ax02)
ax.set(title='Exemplo 02')

y01, sr01 = librosa.load('/content/exemplo01.wav')

S01 = librosa.feature.melspectrogram(y=y01, sr=sr01)
S_dB01 = librosa.power_to_db(S01, ref=np.max)

fig01, ax01 = plt.subplots(figsize=(15, 3))
# fig, ax = plt.figure(figsize=(15, 3))
img01 = librosa.display.specshow(S_dB01, sr=sr01, x_axis='time')
fig01.colorbar(img01, ax=ax01, format='%+2.0f dB')
ax01.set(title='Exemplo 01')

y02, sr02 = librosa.load('/content/exemplo02.wav')

S02 = librosa.feature.melspectrogram(y=y02, sr=sr02)
S_dB02 = librosa.power_to_db(S02, ref=np.max)

fig02, ax02 = plt.subplots(figsize=(15, 3))
# fig, ax = plt.figure(figsize=(15, 3))
img02 = librosa.display.specshow(S_dB02, sr=sr02, x_axis='time')
fig02.colorbar(img02, ax=ax02, format='%+2.0f dB')
ax02.set(title='Exemplo 02')

"""Chroma

A chroma vector is a typically a 12-element feature vector indicating how much energy of each pitch class, {C, C#, D, D#, E, ..., B}, is present in the signal. https://en.wikipedia.org/wiki/Chroma_feature
"""

x01, sr01 = librosa.load('/content/exemplo01.wav')

hop_length01 = 512

chromagram01 = librosa.feature.chroma_stft(x01, sr=sr01, hop_length=hop_length01)
plt.figure(figsize=(15, 5))
librosa.display.specshow(chromagram01, x_axis='time', y_axis='chroma', hop_length=hop_length01, cmap='coolwarm')

x02, sr02 = librosa.load('/content/exemplo02.wav')

hop_length02 = 512

chromagram02 = librosa.feature.chroma_stft(x02, sr=sr02, hop_length=hop_length02)
plt.figure(figsize=(15, 5))
librosa.display.specshow(chromagram02, x_axis='time', y_axis='chroma', hop_length=hop_length02, cmap='coolwarm')

"""Tempogram

Tempo refers to the rate of the musical beat and is given by the reciprocal of the beat period. Tempo is often defined in units of beats per minute (BPM). Tempo can vary locally within a piece. Therefore, we introduce the tempogram (FMP, p. 317) as a feature matrix which indicates the prevalence of certain tempo at each moment in time.
"""

y, sr = librosa.load('/content/exemplo01.wav')
hop_length = 512

# Compute local onset autocorrelation
oenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)
times = librosa.times_like(oenv, sr=sr, hop_length=hop_length)
tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr,
                                      hop_length=hop_length)

# Estimate the global tempo for display purposes
tempo = librosa.beat.tempo(onset_envelope=oenv, sr=sr,
                           hop_length=hop_length)[0]
fig, ax = plt.subplots(nrows=2, figsize=(15, 6))

ax[0].plot(times, oenv, label='Onset strength')
ax[0].label_outer()
ax[0].legend(frameon=True)
librosa.display.specshow(tempogram, sr=sr, hop_length=hop_length,
                         x_axis='time', y_axis='tempo', cmap='magma',
                         ax=ax[1])
ax[1].axhline(tempo, color='w', linestyle='--', alpha=1,
            label='Estimated tempo={:g}'.format(tempo))
ax[1].legend(loc='upper right')
ax[1].set(title='Tempogram')

y, sr = librosa.load('/content/exemplo02.wav')
hop_length = 512

# Compute local onset autocorrelation
oenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)
times = librosa.times_like(oenv, sr=sr, hop_length=hop_length)
tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr,
                                      hop_length=hop_length)

# Estimate the global tempo for display purposes
tempo = librosa.beat.tempo(onset_envelope=oenv, sr=sr,
                           hop_length=hop_length)[0]
fig, ax = plt.subplots(nrows=2, figsize=(15, 6))

ax[0].plot(times, oenv, label='Onset strength')
ax[0].label_outer()
ax[0].legend(frameon=True)
librosa.display.specshow(tempogram, sr=sr, hop_length=hop_length,
                         x_axis='time', y_axis='tempo', cmap='magma',
                         ax=ax[1])
ax[1].axhline(tempo, color='w', linestyle='--', alpha=1,
            label='Estimated tempo={:g}'.format(tempo))
ax[1].legend(loc='upper right')
ax[1].set(title='Tempogram')